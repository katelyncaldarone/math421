df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 1))
fancyRpartPlot(tree3)
set.seed(10000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 23)
fancyRpartPlot(tree3)
set.seed(10000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree2 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 23))
fancyRpartPlot(tree3)
set.seed(10000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree2 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 23))
fancyRpartPlot(tree3)
set.seed(1000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 23))
fancyRpartPlot(tree3)
set.seed(1000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 19))
fancyRpartPlot(tree3)
set.seed(7000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 19))
fancyRpartPlot(tree3)
set.seed(1780)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 19))
fancyRpartPlot(tree3)
set.seed(1780)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 6))
fancyRpartPlot(tree3)
set.seed(2010)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 11))
fancyRpartPlot(tree1)
pred <- predict(tree1, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
#accuracy of tree1
pred <- predict(tree1, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
set.seed(1000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree2 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 30))
fancyRpartPlot(tree2)
#accuracy of tree1
pred <- predict(tree2, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
set.seed(1780)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 6))
fancyRpartPlot(tree3)
#accuracy of tree1
pred <- predict(tree3, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
set.seed(2010)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 11))
fancyRpartPlot(tree1)
#accuracy of tree1
pred <- predict(tree1, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
set.seed(1000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree2 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 30))
fancyRpartPlot(tree2)
#accuracy of tree2
pred <- predict(tree2, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
set.seed(1780)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 6))
fancyRpartPlot(tree3)
#accuracy of tree3
pred <- predict(tree3, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
#accuracy of tree3
pred <- predict(tree3, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
install.packages("randomForest")
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
#install.packages("randomForest")
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
#install.packages("randomForest")
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "">50K", "<50K"")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
importance(forest_model)
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 5000)
pred <- predict(forest_model, df_test, type = "class")
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 2500)
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 1500)
forest_model2 = randomForest(target ~ ., data=df_train, ntree = 500)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 1500)
pred <- predict(forest_model, df_test, type = "class")
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 1500)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model2 = randomForest(target ~ ., data=df_train, ntree = 100)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model2 = randomForest(target ~ ., data=df_train, ntree = 50)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model3 = randomForest(target ~ ., data=df_train, ntree = 5000)
forest_model3 = randomForest(target ~ ., data=df_train, ntree = 5000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
knitr::opts_chunk$set(message = FALSE)
#accuracy of tree2
pred <- predict(tree2, df_test, type = "class")
library(tidyverse)
df <- read_csv('adult_census.csv')
#take out some columns
df <- df %>% select(-fnlwgt, -marital.status, -occupation, -relationship, -capital.gain, -capital.loss)
#set the target variable
df <- df %>% rename(target=income)
#changing character variables to factors
df <- df %>%
mutate(target = as.factor(target),
workclass = as.factor(workclass),
race = as.factor(race),
sex = as.factor(sex),
education = as.factor(education),
native.country = as.factor(native.country)
)
#drop NA values
df = drop_na(df)
#install.packages("caret")
library(caret)
set.seed(2023)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
#install.packages("rpart")
library(rpart)
decision_tree <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 3))
#install.packages("rattle")
library(rattle)
fancyRpartPlot(decision_tree)
decision_tree$variable.importance
barplot(decision_tree$variable.importance)
set.seed(2010)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 11))
fancyRpartPlot(tree1)
#accuracy of tree1
pred <- predict(tree1, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
#accuracy of tree1
pred <- predict(tree1, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
set.seed(1000)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree2 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 30))
fancyRpartPlot(tree2)
#accuracy of tree2
pred <- predict(tree2, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
set.seed(1780)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree3 <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 6))
fancyRpartPlot(tree3)
#accuracy of tree3
pred <- predict(tree3, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
#accuracy of tree3
pred <- predict(tree3, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
#install.packages("randomForest")
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
importance(forest_model)
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 1500)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model2 = randomForest(target ~ ., data=df_train, ntree = 50)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model3 = randomForest(target ~ ., data=df_train, ntree = 5000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 10000)
forest_model2 = randomForest(target ~ ., data=df_train, ntree = 50)
pred <- predict(forest_model2, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K", "<50K")
cm$overall[1]
forest_model3 = randomForest(target ~ ., data=df_train, ntree = 5000)
pred <- predict(forest_model3, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
forest_model1 = randomForest(target ~ ., data=df_train, ntree = 2023)
pred <- predict(forest_model1, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
pred <- predict(decision_tree, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
forest_model3 = randomForest(target ~ ., data=df_train, ntree = 4000)
pred <- predict(forest_model3, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(mlbench)
library(tidyverse)
library(caret)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
#Data Preparation
# Set the target variable
df <- df %>% rename(target=diabetes)
# Handle missing values
df = drop_na(df)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
model4 <- train(target~., data=df_train,
method = "adabag")
model4 <- train(target~., data=df_train,
method = "e1071")
model4 <- train(target~., data=df_train,
method = "M5")
model4 <- train(target~., data=df_train,
method = "M5")
library("Rweka")
library(rweka)
library(RWekajars)
model4 <- train(target~., data=df_train,
method = "M5")
model4 <- train(target~., data=df_train,
method = "M5")
model4 <- train(target~., data=df_train,
method = "M5")
model4 <- train(target~., data=df_train,
method = "M5")
library(RWeka)
model4 <- train(target~., data=df_train,
method = "cvm")
model4 <- train(target~., data=df_train,
method = "pls")
pred <- predict(model4, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
model4 <- train(target~., data=df_train,
method = "pls")
pred <- predict(model4, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
model5 <- train(target~., data=df_train,
method = "rda")
pred <- predict(model5, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
varImp(model4)
plot(varImp(model4))
plot(varImp(model4))
plot(varImp(model5))
varImp(model5)
model5 <- train(target~., data=df_train,
method = "rda")
pred <- predict(model5, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
varImp(model5)
model5 <- train(target~., data=df_train,
method = "glmboost")
pred <- predict(model5, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
varImp(model5)
plot(varImp(model5))
knitr::opts_chunk$set(message = FALSE)
library(mlbench)
library(tidyverse)
library(caret)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
#Data Preparation
# Set the target variable
df <- df %>% rename(target=diabetes)
# Handle missing values
df = drop_na(df)
splitIndex <- createDataPartition(df$target, p = .85,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
trControl = trainControl(method = "cv",
number = 7)
rpart1SE <- train(target~., data=df_train,
method = "rpart1SE",
trControl = trControl)
gaussprLinear <- train(target~., data=df_train,
method = "gaussprLinear",
trControl = trControl)
trControl = trainControl(method = "cv",
number = 7)
rpart1SE <- train(target~., data=df_train,
method = "rpart1SE",
trControl = trControl)
gaussprLinear <- train(target~., data=df_train,
method = "gaussprLinear",
trControl = trControl)
trControl = trainControl(method = "cv",
number = 7)
rpart1SE <- train(target~., data=df_train,
method = "rpart1SE",
trControl = trControl)
glm <- train(target~., data=df_train,
method = "glm",
trControl = trControl)
results <- resamples(list('rpart1SE' = rpart1SE,
'Generalized Linear Model' = glm))
bwplot(results)
pred <- predict(glm, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
pred <- predict(rpart1SE, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
trControl = trainControl(method = "cv",
number = 7)
rpart1SE <- train(target~., data=df_train,
method = "mlda",
trControl = trControl)
trControl = trainControl(method = "cv",
number = 7)
rpart1SE <- train(target~., data=df_train,
method = "mda",
trControl = trControl)
glm <- train(target~., data=df_train,
method = "glm",
trControl = trControl)
results <- resamples(list('rpart1SE' = rpart1SE,
'Generalized Linear Model' = glm))
bwplot(results)
pred <- predict(rpart1SE, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
pred <- predict(glm, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
trControl = trainControl(method = "cv",
number = 7)
mda <- train(target~., data=df_train,
method = "mda",
trControl = trControl)
glm <- train(target~., data=df_train,
method = "null",
trControl = trControl)
results <- resamples(list('Mixture Discriminant Analysis' = rpart1SE,
'Generalized Linear Model' = glm))
bwplot(results)
pred <- predict(null, df_test)
trControl = trainControl(method = "cv",
number = 7)
mda <- train(target~., data=df_train,
method = "mda",
trControl = trControl)
null <- train(target~., data=df_train,
method = "null",
trControl = trControl)
results <- resamples(list('Mixture Discriminant Analysis' = rpart1SE,
'Generalized Linear Model' = glm))
bwplot(results)
pred <- predict(null, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
pred <- predict(mda, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
knitr::opts_chunk$set(message = FALSE)
trControl = trainControl(method = "cv",
number = 7)
library(mlbench)
library(tidyverse)
library(caret)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
trControl = trainControl(method = "cv",
number = 7)
mda <- train(target~., data=df_train,
method = "mda",
trControl = trControl)
null <- train(target~., data=df_train,
method = "null",
trControl = trControl)
results <- resamples(list('Mixture Discriminant Analysis' = rpart1SE,
'Non-Informative Analysis' = glm))
trControl = trainControl(method = "cv",
number = 7)
mda <- train(target~., data=df_train,
method = "mda",
trControl = trControl)
